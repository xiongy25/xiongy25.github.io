# 双足机器人研究与项目

## 1. 人形机器人平台

- [SMPL Olympics](https://github.com/SMPLOlympics/SMPLOlympics) - 专注于人体运动的项目
- [Humanoid-Gym](https://github.com/roboterax/humanoid-gym.git) - 使用 Zero-Sim2Real 迁移进行人形机器人强化学习
- [伯克利人形机器人](https://berkeley-humanoid.com/) - 基于学习的控制研究平台
- [Zeroth 机器人](https://github.com/zeroth-robotics/zeroth-bot) - 3D打印开源人形机器人平台，适用于模拟到现实和RL
  - [姿势镜像系统](https://github.com/theswerd/basedbot) - 让Zeroth机器人实时镜像人体姿势
- [stable-humanoid](https://github.com/ouazzmoh/stable-humanoid) - 基于模型预测控制的人形机器人稳定行走基准测试工具
- [human2humanoid](https://github.com/LeCAR-Lab/human2humanoid) - 实现人类到人形机器人的实时全身远程操控
- [Berkeley-Humanoid-Lite](https://github.com/HybridRobotics/Berkeley-Humanoid-Lite.git) - 伯克利人形机器人精简版
- [booster_gym](https://booster-gym.github.io/) - Booster Gym 是由 Booster Robotics 开发的专为人形机器人运动而设计的强化学习 (RL) 框架
- [Robocup Demo](https://github.com/BoosterRobotics/robocup_demo.git) - 《BoosterRobotics/robocup_demo：Booster T1 Robocup 官方演示允许机器人自主决策踢球并完成整个 Robocup 比赛。它包括三个程序：视觉、大脑和游戏控制器
- [HumanoidVerse](https://github.com/LeCAR-Lab/HumanoidVerse.git) - 支持多种模拟器和任务，用于人形机器人从模拟到现实的学习。其关键设计逻辑是将模拟器、任务和算法分离并模块化，从而方便地在模拟器和任务之间切换，并以最小的投入开发新的模拟器和任务。
- [ToddlerBot](https://github.com/hshi74/toddlerbot.git) - 一个低成本、开源的人形机器人平台，旨在实现可扩展的策略学习以及机器人和人工智能研究
<img width="3024" height="2722" alt="image" src="https://github.com/user-attachments/assets/bccd1296-7dc1-4eb3-aace-ff1cf18444ea" />
- [MEVITA](https://haraduka.github.io/mevita-hardware/) - 开源双足机器人，通过金属板焊接由电子商务组件组装而成
- [unitree_sim_isaaclab](https://github.com/unitreerobotics/unitree_sim_isaaclab.git) - 基于Isaac Lab搭建的Unitree仿真环境
  <img width="2524" height="1377" alt="image" src="https://github.com/user-attachments/assets/ccbdba4e-0c49-4a09-bdbf-28db6f2f8f5f" />

  
## 2. 迪士尼 BDX 相关项目

- [Open Duck Mini](https://github.com/apirrone/Open_Duck_Mini) - 迪士尼 BDX 机器人的迷你版本
  - [isaacgym仿真](https://github.com/apirrone/AMP_for_hardware/tree/bdx) - Open Duck Mini的Isaac Gym仿真环境
  - [isaaclab仿真](https://github.com/MankaranSingh/IsaacLab/tree/eye-candy) - Open Duck Mini的IsaacLab仿真环境
- [Tinker](https://github.com/Yuexuan9/Tinker) - 国内开源版的迪士尼 BDX 机器人
- [Disney BD-X USD Description](https://github.com/louislelay/Disney-BDX-USD-Description.git)
- [bdx_walk_rl](https://github.com/benoit-robotics/bdx_walk_rl.git)
- [Adverserial Waddle Dynamics](https://github.com/rimim/AWD.git) - 使用Isaac Gym训练迪士尼BDX机器人
- [OmniBot系列-Tinker](https://github.com/golaced/OmniBotSeries-Tinker.git) - 打造融合皮克斯与迪士尼BDX的高性能双足机器人！
  <img width="936" height="1329" alt="image" src="https://github.com/user-attachments/assets/a8f4e1ae-3523-40a6-896e-271aabb5dc95" />

## 3. 其他双足机器人项目

- [robocasa](https://github.com/robocasa/robocasa) - 用于训练通用机器人执行日常任务的大规模模拟框架
- [Unitree Go2/G1 数字孪生项目](https://github.com/abizovnuralem/go2_omniverse) - Unitree机器人的数字孪生系统
- [模块化双足机器人项目](https://github.com/makerforgetech/modular-biped) - 开源模块化双足机器人设计
- [Legolas](https://github.com/daviddoo02/Legolas-an-open-source-biped) - 仿cassie的迷你机器人
- [Unitree Robots强化学习方案](https://github.com/unitreerobotics/unitree_rl_gym) - Unitree机器人进行强化学习的全套方案
- [动态腿部运动研究](https://github.com/hojae-io/ModelBasedFootstepPlanning-IROS2024) - 将基于模型的脚步规划与无模型强化学习相结合，实现动态腿部运动
- [rl-deploy-ros-cpp](https://github.com/limxdynamics/rl-deploy-ros-cpp.git) - 在gazebo中使用训练出的RL模型控制机器人
- [Robotic_Studio_Bipedal_Robot](https://github.com/Anthony-ZC/Robotic_Studio_Bipedal_Robot.git) - 哥伦比亚机器人工作室项目实施：代码、CAD、3mf等
- [TienKung-Lab](https://github.com/Open-X-Humanoid/TienKung-Lab.git) - 天工机器人参加人形机器人马拉松的运动控制
- [engineai_legged_gym](https://github.com/engineai-robotics/engineai_legged_gym.git) - 众擎机器人为engineai-robots提供isaac gym环境的RL训练环境

## 4. 人形机器人控制与动作生成

- [PyRoki](https://pyroki-toolkit.github.io/) - A Modular Toolkit for Robot Kinematic Optimization
  <img width="796" height="839" alt="image" src="https://github.com/user-attachments/assets/2ee9f6a4-c483-4de4-b960-c93ad5c6ffe7" />
- [PHC](https://github.com/ZhengyiLuo/PHC) - 基于物理的人形控制器
- [HOVER](https://hover-versatile-humanoid.github.io/) - 人形机器人的多功能神经全身控制器
- [感知内部模型](https://junfeng-long.github.io/PIM/) - 利用感知内部模型学习人形运动
- [UH-1](https://usc-gvl.github.io/UH-1/) - 通过大量人体视频进行学习，实现通用人形姿势控制
- [PDP](https://stanford-tml.github.io/PDP.github.io/) - 基于物理的扩散策略角色动画
- [ASAP](https://agile.human2humanoid.com/) - 协调模拟和现实世界的物理学习敏捷的人形全身技能
- [BeamDojo](https://why618188.github.io/beamdojo/) - 学习在稀疏立足点上进行敏捷的人形运动
- [Embrace Collisions](https://project-instinct.github.io/) - 可部署的接触无关运动的人形阴影技术
- [OmniH2O](https://omni.human2humanoid.com/) - 通用灵巧的人机全身远程操作和学习
- [Exbody2](https://exbody2.github.io/) - 高级富有表现力的人形全身控制
- [RECIPE](https://toruowo.github.io/recipe/) - 基于视觉的人形机器人灵巧操作的模拟到现实强化学习
- [HumanUP](https://humanoid-getup.github.io/) - 学习现实世界人形机器人的起身策略
  ![image](https://github.com/user-attachments/assets/d3afd420-14ca-4a4c-939e-3d0c771b5b50)
- [Humanoid Policy](https://github.com/RogerQi/human-policy.git) - 使用头戴摄像头捕捉数据然后用于训练机器人
  ![image](https://github.com/user-attachments/assets/e144b627-e5bf-4e3d-9203-d2c5523cfa44)
- [Puffer PHC](https://github.com/kywch/puffer-phc.git) - 简化版 Pufferlib、CARBS 的永久性人形控制
  ![image](https://github.com/user-attachments/assets/f81664bb-0058-4ef6-acc6-91638c9ec1c4)
- [FLAM](https://xianqi-zhang.github.io/FLAM/) - 基于基础模型的人形机器人步态和操作稳定化
  ![image](https://github.com/user-attachments/assets/cfdffd2e-b7c8-478c-83b3-bb68e6fc74f8)
- [HoST](https://github.com/OpenRobotLab/HoST.git) - 人形站立控制
  ![image](https://github.com/user-attachments/assets/c0e412a3-4588-4509-a316-cd84c44035ce)
- [LangWBC](https://langwbc.github.io/) - 通过端到端学习实现语言导向的人形机器人全身控制
- [ALMI-Open](https://almi-humanoid.github.io/) - 人形策略学习中的对抗性运动和运动模仿
  ![image](https://github.com/user-attachments/assets/3ff9a2d3-41b4-47c9-b4fb-24d669ea9fca)
- [VideoMimic](https://www.videomimic.net/) - 通过视觉模仿实现人形场景控制
- [HuB](https://hub-robot.github.io/) - 学习人形的极限平衡
- [OpenWBT](https://github.com/GalaxyGeneralRobotics/OpenWBT.git) - 该代码库基于 Apple Vision Pro 实现了 Unitree G1 和 H1 人形机器人的全身遥操作。系统支持真实机器人和仿真环境
- [GMT](https://github.com/zixuan417/humanoid-general-motion-tracking.git) - GMT 是一个统一策略（unified policy），使用大规模人类动作数据训练，使机器人能执行包括走路、跳舞、踢腿、下蹲、武术等全身运动，而不需要为每种动作分别训练控制器。
- [KungfuBot](https://github.com/TeleHuman/PBHC.git) - 基于物理的人形全身控制，用于学习高动态技能
- [Stage-Wise-CMORL](https://github.com/rllab-snu/Stage-Wise-CMORL.git) - 这是论文“杂技机器人的分阶段奖励塑造：一种受约束的多目标强化学习方法”的官方 GitHub 存储库。可以实现Unitree go1和Unitree H1机器人的后空翻动作
- [AMO](https://github.com/OpenTeleVision/AMO.git) - 超灵巧人形机器人全身控制的自适应运动优化
  ![image](https://github.com/user-attachments/assets/a55bc7d2-34c1-4ad5-b362-2c1b2a9822a6)
- [LeVERB](https://ember-lab-berkeley.github.io/LeVERB-Website/) - 利用潜在视觉语言指令进行人形全身控制
  ![image](https://github.com/user-attachments/assets/5327ebff-c99a-4da0-93eb-c50d71b47ec1)
- [RoboMimic Deploy](https://github.com/ccrpRepo/RoboMimic_Deploy.git) - 一个基于状态切换机制的多策略机器人部署框架。目前，其包含的策略专为 Unitree G1 机器人（29 自由度）设计
- [FALCON](https://github.com/LeCAR-Lab/FALCON.git) - 学习力自适应人形机器人操控
  <img width="2992" height="1874" alt="image" src="https://github.com/user-attachments/assets/3f3296fa-3f39-4d19-b627-e84b5485d03e" />
- [Robot Drummer](https://robotdrummer.github.io/) - 学习人形鼓的节奏技巧
  <img width="2652" height="1024" alt="image" src="https://github.com/user-attachments/assets/077bb2d3-a337-498c-9e54-99e16ce7f38e" />
- [GMR](https://github.com/YanjieZe/GMR.git) - 通用运动重定向,利用CPU实时将人体运动重定向到各种人形机器人上。
- [Behavior Foundation Model for Humanoid Robots](https://bfm4humanoid.github.io/) - 人形机器人行为基础模型
  <img width="1899" height="1132" alt="image" src="https://github.com/user-attachments/assets/d549ceb0-0008-4c5d-a5ee-de257ce18f81" />
- [HDMI](https://hdmi-humanoid.github.io/#/) - 捕获人体的动作，并通过 HDMI 接口将动作数据实时传输给人形机器人，使其能够模拟和复现这些动作
- [DreamControl](https://genrobo.github.io/DreamControl/) - 通过引导扩散实现场景交互的受人类启发的全身类人控制
<img width="604" height="340" alt="image" src="https://github.com/user-attachments/assets/5dd179b4-0045-41a4-9a4d-6861d67b10da" />
- [VisualMimic](https://visualmimic.github.io/) - 通过运动跟踪和生成实现视觉人形定位操纵
  <img width="1258" height="823" alt="image" src="https://github.com/user-attachments/assets/0043da62-2c7f-4630-928a-650235658119" />
- [MindLoongGPT](https://github.com/loongOpen/MindLoongGPT.git) - MindLoongGPT 是全球首款生成式人形机器人运动大模型，支持从自然语言输入到机器人动作生成的完整流程
- [Any2Track](https://zzk273.github.io/Any2Track/) - 旨在实现人型机器人在各种现实世界环境扰动下的多样化、高动态和接触丰富的运动跟踪。

## 5.运动重定向
- [HoloMotion](https://github.com/HorizonRobotics/HoloMotion.git) - HoloMotion 是一个统一的基础模型，旨在实现人形机器人的稳健、实时且通用的全身追踪。HoloMotion 基于高保真运动捕捉数据和先进的重定向技术，跨越各种地形和形态，弥合了人体运动与机器人控制之间的差距。该框架支持从数据准备到实际部署的完整流程，包括运动重定向、基于强化学习和运动先验的分布式训练、性能评估以及基于 ROS2 的部署。HoloMotion 采用模块化设计，使人形代理能够在模拟和物理世界中模拟并泛化全身运动。
- [BeyondMimic](https://github.com/HybridRobotics/whole_body_tracking.git) - BeyondMimic 是一个多功能的人形控制框架，可在实际部署中提供具有最先进运动质量的高度动态运动跟踪，并通过基于引导扩散的控制器提供可操纵的测试时间控制
- [General Motion Tracking for Humanoid Whole-Body Control](https://github.com/zixuan417/humanoid-general-motion-tracking.git) - 此代码库支持在 Unitree G1 机器人上进行 Mujoco 运动跟踪模拟。提供了一个预训练的检查点和多个示例动作,此代码库轻量级且易于使用.
- [UH-1](https://github.com/sihengz02/UH-1.git) - 从大量人体视频中学习通用人形姿势控制
- [Lafan1_retarget](https://github.com/wenconggan/Lafan1_retarget.git) - 使用Lafan1数据集实现unitree g1的重定向运动
  <img width="915" height="625" alt="image" src="https://github.com/user-attachments/assets/5b3c860d-0922-4008-9795-57ccaaa52621" />
- [recap](https://github.com/RumblingTurtle/recap.git) - 一个专门为人形机器人设计的运动捕捉重定向库,弥合了人类运动和机器人运动之间的差距，让机器人能够学习和模仿人类的自然动作
  <img width="320" height="240" alt="image" src="https://github.com/user-attachments/assets/f7dda74e-ae65-4c57-b50f-cdf27b3fd325" />
- [TWIST](https://github.com/YanjieZe/TWIST.git) - 一个利用全身人类运动数据实时遥控人形机器人的系统，能够执行多样化和协调的全身动作


## 6. 开源数据集

- [Isaac-GR00T](https://github.com/NVIDIA/Isaac-GR00T.git) - NVIDIA Isaac GR00T N1 是世界上第一个用于通用人形机器人推理和技能的开放基础模型
- [unitree开源全身运动数据集](https://huggingface.co/datasets/unitreerobotics/LAFAN1_Retargeting_Dataset) -  Unitree H1、H1-2 和 G1 人形机器人的动作捕捉数据，使用数值优化方法使它们的运动轨迹更加自然

